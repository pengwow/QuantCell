# -*- coding: utf-8 -*-
"""
å›æµ‹CLIæ ¸å¿ƒé€»è¾‘æ¨¡å—

æä¾›å›æµ‹CLIçš„æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®å‡†å¤‡ï¼ˆæ£€æŸ¥å®Œæ•´æ€§+è‡ªåŠ¨ä¸‹è½½ï¼‰
- ç­–ç•¥åŠ è½½
- å›æµ‹æ‰§è¡Œ
- ç»“æœåˆ†æ
- ç³»ç»Ÿé…ç½®è¯»å–
"""

import importlib
import json
import os
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from loguru import logger

# æ·»åŠ ç­–ç•¥ç›®å½•åˆ°è·¯å¾„
backend_path = Path(__file__).resolve().parent.parent
strategies_dir = backend_path / 'strategies'
if str(strategies_dir) not in sys.path:
    sys.path.insert(0, str(strategies_dir))

from backtest.progress import ConsoleProgressBar, ProgressTracker
from backtest.result_analysis import output_results
from strategy.core import StrategyBase
from strategy.adapters import VectorBacktestAdapter, PortfolioBacktestAdapter
from utils.time_parser import parse_time_range, datetime_to_timestamp
from utils.validation import parse_symbols, parse_timeframes


class DownloadFailureType(Enum):
    """ä¸‹è½½å¤±è´¥ç±»å‹"""
    NO_DATA_AVAILABLE = "no_data_available"  # æ•°æ®æºæ— å¯ç”¨æ•°æ®
    NETWORK_ERROR = "network_error"          # ç½‘ç»œé”™è¯¯
    TIMEOUT = "timeout"                      # è¶…æ—¶
    UNKNOWN = "unknown"                      # æœªçŸ¥é”™è¯¯


@dataclass
class DataDownloadResult:
    """æ•°æ®ä¸‹è½½ç»“æœ"""
    symbol: str
    timeframe: str
    success: bool
    failure_type: Optional[DownloadFailureType] = None
    failure_reason: Optional[str] = None
    data: Optional[pd.DataFrame] = None
    warnings: List[str] = field(default_factory=list)  # è­¦å‘Šä¿¡æ¯åˆ—è¡¨
    is_incomplete: bool = False  # æ•°æ®æ˜¯å¦ä¸å®Œæ•´
    coverage_percent: float = 100.0  # æ•°æ®è¦†ç›–ç‡


class DataPreparationError(Exception):
    """æ•°æ®å‡†å¤‡å¼‚å¸¸"""
    pass


class StrategyLoadError(Exception):
    """ç­–ç•¥åŠ è½½å¼‚å¸¸"""
    pass


class BacktestExecutionError(Exception):
    """å›æµ‹æ‰§è¡Œå¼‚å¸¸"""
    pass


class CLICore:
    """CLIæ ¸å¿ƒé€»è¾‘ç±»"""

    def __init__(self, verbose: bool = False, detail: bool = False, standalone_mode: bool = True):
        """
        åˆå§‹åŒ–CLIæ ¸å¿ƒ

        å‚æ•°ï¼š
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
            detail: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†äº¤æ˜“è¾“å‡ºï¼ˆä¹°å…¥/å–å‡º/æŒä»“æ›´æ–°ç­‰ï¼‰
            standalone_mode: æ˜¯å¦ä½¿ç”¨ç‹¬ç«‹æ¨¡å¼ï¼ˆä¸ä¾èµ–FastAPIæœåŠ¡ï¼‰
        """
        self.verbose = verbose
        self.detail = detail
        self.standalone_mode = standalone_mode
        self.results_dir = backend_path / 'backtest' / 'results'
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç‹¬ç«‹ä¸‹è½½å™¨
        if standalone_mode:
            from backtest.data_downloader import BacktestDataDownloader
            self.downloader = BacktestDataDownloader(standalone_mode=True)
        
    def prepare_data(
        self,
        symbols: List[str],
        timeframes: List[str],
        time_range: Optional[str],
        trading_mode: str,
        auto_download: bool = True,
        ignore_missing: bool = False,
        show_progress: bool = True
    ) -> Tuple[Dict[str, pd.DataFrame], List[DataDownloadResult]]:
        """
        å‡†å¤‡å›æµ‹æ•°æ®ï¼Œè‡ªåŠ¨æ£€æŸ¥å®Œæ•´æ€§å¹¶ä¸‹è½½ç¼ºå¤±æ•°æ®

        å‚æ•°ï¼š
            symbols: è´§å¸å¯¹åˆ—è¡¨
            timeframes: æ—¶é—´å‘¨æœŸåˆ—è¡¨
            time_range: æ—¶é—´èŒƒå›´å­—ç¬¦ä¸²ï¼ˆYYYYMMDD-YYYYMMDDï¼‰
            trading_mode: äº¤æ˜“æ¨¡å¼ï¼ˆspot/futures/perpetualï¼‰
            auto_download: æ˜¯å¦è‡ªåŠ¨ä¸‹è½½ç¼ºå¤±æ•°æ®
            ignore_missing: æ˜¯å¦å¿½ç•¥æ•°æ®ç¼ºå¤±ï¼Œå…è®¸ä¸å®Œæ•´æ•°æ®ç»§ç»­å›æµ‹
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        è¿”å›ï¼š
            Tuple[Dict[str, pd.DataFrame], List[DataDownloadResult]]:
                (æˆåŠŸåŠ è½½çš„æ•°æ®å­—å…¸, æ‰€æœ‰ä¸‹è½½ç»“æœåˆ—è¡¨)

        å¼‚å¸¸ï¼š
            DataPreparationError: æ•°æ®å‡†å¤‡å¤±è´¥
        """
        from backtest.data_integrity import DataIntegrityChecker
        
        # è§£ææ—¶é—´èŒƒå›´
        start_date, end_date = parse_time_range(time_range)
        
        # åˆå§‹åŒ–æ£€æŸ¥å™¨å’Œä¸‹è½½å™¨
        checker = DataIntegrityChecker()
        
        # ä½¿ç”¨ç‹¬ç«‹ä¸‹è½½å™¨ï¼ˆå¦‚æœå·²åˆå§‹åŒ–ï¼‰
        if not hasattr(self, 'downloader') or self.downloader is None:
            from backtest.data_downloader import BacktestDataDownloader
            self.downloader = BacktestDataDownloader(standalone_mode=self.standalone_mode)
        
        data_dict = {}
        download_results: List[DataDownloadResult] = []
        total_tasks = len(symbols) * len(timeframes)
        current_task = 0
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = None
        if show_progress:
            progress_bar = ConsoleProgressBar(total=total_tasks, desc="æ•°æ®å‡†å¤‡")
            progress_bar.start_animation()  # å¯åŠ¨åå°åŠ¨ç”»çº¿ç¨‹

        try:
            for symbol in symbols:
                for timeframe in timeframes:
                    current_task += 1
                    key = f"{symbol}_{timeframe}"

                    if show_progress and progress_bar:
                        progress_bar.set_message(f"ğŸ” æ£€æŸ¥ {key} æ•°æ®å®Œæ•´æ€§...")
                    else:
                        logger.info(f"[{current_task}/{total_tasks}] å‡†å¤‡æ•°æ®: {key}")

                    try:
                        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                        integrity_result = None
                        if start_date and end_date:
                            integrity_result = checker.check_data_completeness(
                                symbol=symbol,
                                interval=timeframe,
                                start_time=start_date,
                                end_time=end_date,
                                market_type='crypto',
                                crypto_type=trading_mode
                            )

                            # å¦‚æœæ•°æ®ä¸å®Œæ•´
                            if not integrity_result.is_complete:
                                missing_percentage = 100.0 - integrity_result.coverage_percent if hasattr(integrity_result, 'coverage_percent') else 0

                                # å¦‚æœå…è®¸å¿½ç•¥ç¼ºå¤±æ•°æ®ï¼Œè®°å½•è­¦å‘Šå¹¶ç»§ç»­
                                if ignore_missing:
                                    if show_progress and progress_bar:
                                        progress_bar.set_message(f"âš ï¸  {key} æ•°æ®ä¸å®Œæ•´ ({missing_percentage:.1f}%)ï¼Œå·²å¿½ç•¥")
                                    logger.warning(f"  âš ï¸ {key} æ•°æ®ä¸å®Œæ•´ ({missing_percentage:.1f}%)ï¼Œæ ¹æ® --ignore-missing å‚æ•°ç»§ç»­")
                                # å¦‚æœå…è®¸è‡ªåŠ¨ä¸‹è½½ï¼Œå°è¯•ä¸‹è½½ç¼ºå¤±æ•°æ®
                                elif auto_download:
                                    if show_progress and progress_bar:
                                        progress_bar.set_message(f"â¬‡ï¸  ä¸‹è½½ {key} ç¼ºå¤±æ•°æ® ({missing_percentage:.1f}%)...")
                                    else:
                                        logger.info(f"  å‘ç°æ•°æ®ç¼ºå¤± {missing_percentage:.1f}%ï¼Œå¼€å§‹ä¸‹è½½...")

                                    download_success, _ = self.downloader.ensure_data_complete(
                                        symbol=symbol,
                                        interval=timeframe,
                                        start_time=start_date,
                                        end_time=end_date,
                                        market_type='crypto',
                                        crypto_type=trading_mode
                                    )

                                    if not download_success:
                                        if show_progress and progress_bar:
                                            progress_bar.set_message(f"âš ï¸  {key} æ•°æ®ä¸‹è½½å¤±è´¥")
                                        logger.warning(f"  è­¦å‘Š: {key} æ•°æ®ä¸‹è½½å¤±è´¥æˆ–ä»ä¸å®Œæ•´")
                                else:
                                    if show_progress and progress_bar:
                                        progress_bar.set_message(f"âš ï¸  {key} æ•°æ®ä¸å®Œæ•´ ({missing_percentage:.1f}%)")
                                    logger.warning(f"  âš ï¸ {key} æ•°æ®ä¸å®Œæ•´ ({missing_percentage:.1f}%)")
                            else:
                                if show_progress and progress_bar:
                                    progress_bar.set_message(f"âœ… {key} æ•°æ®å®Œæ•´")

                        # ä»æ•°æ®åº“åŠ è½½æ•°æ®
                        if show_progress and progress_bar:
                            progress_bar.set_message(f"ğŸ“Š åŠ è½½ {key} æ•°æ®...")

                        df = self._load_klines_from_db(
                            symbol=symbol,
                            timeframe=timeframe,
                            start_date=start_date,
                            end_date=end_date,
                            trading_mode=trading_mode
                        )

                        if df is not None and not df.empty:
                            data_dict[key] = df

                            # æ”¶é›†æ•°æ®å®Œæ•´æ€§ä¿¡æ¯
                            result_warnings = []
                            result_is_incomplete = False
                            result_coverage_percent = 100.0

                            # åªæœ‰å½“æ•°æ®ç¡®å®ç¼ºå¤±ï¼ˆè¦†ç›–ç‡<100%ï¼‰æ—¶æ‰æ ‡è®°ä¸ºä¸å®Œæ•´
                            if integrity_result and integrity_result.coverage_percent < 100.0:
                                result_is_incomplete = True
                                result_coverage_percent = integrity_result.coverage_percent
                                missing_pct = 100.0 - integrity_result.coverage_percent
                                result_warnings.append(
                                    f"æ•°æ®ä¸å®Œæ•´ï¼Œè¦†ç›–ç‡ {integrity_result.coverage_percent:.1f}%ï¼Œç¼ºå¤± {missing_pct:.1f}%"
                                )

                            download_results.append(DataDownloadResult(
                                symbol=symbol,
                                timeframe=timeframe,
                                success=True,
                                data=df,
                                warnings=result_warnings,
                                is_incomplete=result_is_incomplete,
                                coverage_percent=result_coverage_percent
                            ))

                            if show_progress and progress_bar:
                                status_msg = f"âœ“ {key}: {len(df)} æ¡æ•°æ®"
                                if result_is_incomplete:
                                    status_msg = f"âœ“ {key}: {len(df)} æ¡æ•°æ® (ä¸å®Œæ•´ {result_coverage_percent:.1f}%)"
                                progress_bar.set_message(status_msg)
                            logger.info(f"  âœ“ æˆåŠŸåŠ è½½ {key}: {len(df)} æ¡æ•°æ®")
                        else:
                            # æ•°æ®ä¸ºç©ºï¼Œåˆ¤æ–­å¤±è´¥ç±»å‹
                            failure_type = self._determine_failure_type(symbol, trading_mode)
                            failure_reason = f"æ— æ³•è·å– {symbol} {timeframe} çš„æ•°æ®"

                            if failure_type == DownloadFailureType.NO_DATA_AVAILABLE:
                                failure_reason = f"æ•°æ®æºæ— å¯ç”¨æ•°æ®: {symbol}"
                                if show_progress and progress_bar:
                                    progress_bar.set_message(f"âš ï¸  {key} æ— å¯ç”¨æ•°æ®")
                                logger.warning(f"  âš ï¸ {failure_reason}")
                            else:
                                if show_progress and progress_bar:
                                    progress_bar.set_message(f"âœ— {key} æœªæ‰¾åˆ°æ•°æ®")
                                logger.warning(f"  âœ— æœªæ‰¾åˆ° {key} çš„æ•°æ®")

                            download_results.append(DataDownloadResult(
                                symbol=symbol,
                                timeframe=timeframe,
                                success=False,
                                failure_type=failure_type,
                                failure_reason=failure_reason
                            ))

                    except Exception as e:
                        # å¤„ç†å¼‚å¸¸
                        failure_type = DownloadFailureType.UNKNOWN
                        failure_reason = str(e)

                        if show_progress and progress_bar:
                            progress_bar.set_message(f"âœ— {key} å¤„ç†é”™è¯¯")

                        download_results.append(DataDownloadResult(
                            symbol=symbol,
                            timeframe=timeframe,
                            success=False,
                            failure_type=failure_type,
                            failure_reason=failure_reason
                        ))
                        logger.error(f"  âœ— å¤„ç† {key} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

                    if show_progress and progress_bar:
                        progress_bar.update(1)

            if show_progress and progress_bar:
                progress_bar.stop_animation()  # åœæ­¢åŠ¨ç”»çº¿ç¨‹
                progress_bar.finish("æ•°æ®å‡†å¤‡å®Œæˆ")
            
            return data_dict, download_results
            
        except Exception as e:
            raise DataPreparationError(f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
    
    def _load_klines_from_db(
        self,
        symbol: str,
        timeframe: str,
        start_date: Optional[datetime],
        end_date: Optional[datetime],
        trading_mode: str
    ) -> Optional[pd.DataFrame]:
        """
        ä»æ•°æ®åº“åŠ è½½Kçº¿æ•°æ®
        
        å‚æ•°ï¼š
            symbol: è´§å¸å¯¹
            timeframe: æ—¶é—´å‘¨æœŸ
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            trading_mode: äº¤æ˜“æ¨¡å¼
            
        è¿”å›ï¼š
            Optional[pd.DataFrame]: Kçº¿æ•°æ®DataFrame
        """
        from collector.db.connection import get_db_connection
        from collector.db.models import CryptoSpotKline, CryptoFutureKline
        
        try:
            conn = get_db_connection()
            
            # æ ‡å‡†åŒ–symbolæ ¼å¼ï¼ˆå»é™¤/ï¼‰
            normalized_symbol = symbol.replace('/', '')
            
            # é€‰æ‹©æ•°æ®è¡¨
            if trading_mode == 'spot':
                KlineModel = CryptoSpotKline
            elif trading_mode in ['futures', 'perpetual']:
                KlineModel = CryptoFutureKline
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„äº¤æ˜“æ¨¡å¼: {trading_mode}")
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            conditions = f"symbol = '{normalized_symbol}' AND interval = '{timeframe}'"
            if start_date:
                start_timestamp = datetime_to_timestamp(start_date)
                conditions += f" AND CAST(timestamp AS INTEGER) >= {start_timestamp}"
            if end_date:
                end_timestamp = datetime_to_timestamp(end_date)
                conditions += f" AND CAST(timestamp AS INTEGER) <= {end_timestamp}"
            
            # ç”ŸæˆSQL
            query = f"""
                SELECT timestamp, open, high, low, close, volume
                FROM {KlineModel.__tablename__}
                WHERE {conditions}
                ORDER BY timestamp ASC
            """
            
            # æ‰§è¡ŒæŸ¥è¯¢
            cursor = conn.cursor()
            cursor.execute(query)
            klines = cursor.fetchall()
            
            # è½¬æ¢ä¸ºDataFrame
            if klines:
                df = pd.DataFrame(
                    klines, 
                    columns=['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']
                )
                # æ—¶é—´æˆ³è½¬æ¢
                df['timestamp'] = pd.to_datetime(df['timestamp'].astype(float) / 1000, unit='s')
                df.set_index('timestamp', inplace=True)
                return df
            else:
                return None
                
        except Exception as e:
            logger.error(f"åŠ è½½Kçº¿æ•°æ®å¤±è´¥: {symbol} {timeframe}, é”™è¯¯: {e}")
            return None
    
    def _determine_failure_type(
        self,
        symbol: str,
        trading_mode: str = 'spot'
    ) -> DownloadFailureType:
        """
        åˆ¤æ–­ä¸‹è½½å¤±è´¥ç±»å‹
        
        é€šè¿‡æ£€æŸ¥æ•°æ®åº“ä¸­çš„symbolåˆ—è¡¨ç¡®è®¤æ˜¯å¦ä¸ºæ•°æ®æºæ— æ•°æ®
        
        å‚æ•°ï¼š
            symbol: è´§å¸å¯¹
            trading_mode: äº¤æ˜“æ¨¡å¼
            
        è¿”å›ï¼š
            DownloadFailureType: å¤±è´¥ç±»å‹
        """
        try:
            from collector.db.database import SessionLocal, init_database_config
            from collector.db.models import CryptoSymbol
            
            # åˆå§‹åŒ–æ•°æ®åº“
            init_database_config()
            db = SessionLocal()
            
            # æ ‡å‡†åŒ–symbolæ ¼å¼ï¼ˆå»é™¤/ï¼‰
            normalized_symbol = symbol.replace('/', '')
            
            try:
                # æŸ¥è¯¢æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨è¯¥symbol
                symbol_record = db.query(CryptoSymbol).filter(
                    CryptoSymbol.symbol == normalized_symbol,
                    CryptoSymbol.exchange == 'binance',
                    CryptoSymbol.is_active == True
                ).first()
                
                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰è¯¥symbolè®°å½•ï¼Œè¯´æ˜æ•°æ®æºæ— æ­¤èµ„äº§
                if symbol_record is None:
                    return DownloadFailureType.NO_DATA_AVAILABLE
                
                # å¦‚æœsymbolå­˜åœ¨ä½†è¢«æ ‡è®°ä¸ºinactiveï¼Œä¹Ÿå¯èƒ½æ˜¯æ— æ•°æ®
                if not symbol_record.is_active:
                    return DownloadFailureType.NO_DATA_AVAILABLE
                
                # å…¶ä»–æƒ…å†µè®¤ä¸ºæ˜¯ç½‘ç»œæˆ–æœªçŸ¥é”™è¯¯
                return DownloadFailureType.UNKNOWN
                
            finally:
                db.close()
            
        except Exception:
            # å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œè¿”å›æœªçŸ¥
            return DownloadFailureType.UNKNOWN
    
    def load_strategy(
        self,
        strategy_name: str,
        strategy_params: Dict[str, Any]
    ) -> StrategyBase:
        """
        åŠ è½½ç­–ç•¥
        
        å‚æ•°ï¼š
            strategy_name: ç­–ç•¥åç§°ï¼ˆæ–‡ä»¶åï¼Œä¸å«.pyåç¼€ï¼‰
            strategy_params: ç­–ç•¥å‚æ•°
            
        è¿”å›ï¼š
            StrategyBase: ç­–ç•¥å®ä¾‹
            
        å¼‚å¸¸ï¼š
            StrategyLoadError: ç­–ç•¥åŠ è½½å¤±è´¥
        """
        try:
            # æ¸…é™¤æ¨¡å—ç¼“å­˜
            if strategy_name in sys.modules:
                del sys.modules[strategy_name]
            
            # æ£€æŸ¥ç­–ç•¥æ–‡ä»¶
            strategy_file = strategies_dir / f"{strategy_name}.py"
            if not strategy_file.exists():
                raise StrategyLoadError(f"ç­–ç•¥æ–‡ä»¶ä¸å­˜åœ¨: {strategy_file}")
            
            # å¯¼å…¥ç­–ç•¥æ¨¡å—
            module = importlib.import_module(strategy_name)
            
            # æŸ¥æ‰¾ç­–ç•¥ç±»
            strategy_class = None
            for name in dir(module):
                obj = getattr(module, name)
                if isinstance(obj, type) and issubclass(obj, StrategyBase) and obj != StrategyBase:
                    strategy_class = obj
                    logger.info(f"æ‰¾åˆ°ç­–ç•¥ç±»: {name}")
                    break
            
            if strategy_class is None:
                raise StrategyLoadError(f"åœ¨æ¨¡å— {strategy_name} ä¸­æ‰¾ä¸åˆ°ç­–ç•¥ç±»")
            
            # åˆ›å»ºç­–ç•¥å®ä¾‹
            strategy = strategy_class(strategy_params)
            logger.info(f"æˆåŠŸåŠ è½½ç­–ç•¥: {strategy_class.__name__}")
            
            return strategy
            
        except Exception as e:
            raise StrategyLoadError(f"åŠ è½½ç­–ç•¥å¤±è´¥: {e}")
    
    def run_backtest(
        self,
        strategy: StrategyBase,
        data_dict: Dict[str, pd.DataFrame],
        config: Dict[str, Any],
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå›æµ‹
        
        å‚æ•°ï¼š
            strategy: ç­–ç•¥å®ä¾‹
            data_dict: æ•°æ®å­—å…¸
            config: å›æµ‹é…ç½®
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        è¿”å›ï¼š
            Dict[str, Any]: å›æµ‹ç»“æœ
            
        å¼‚å¸¸ï¼š
            BacktestExecutionError: å›æµ‹æ‰§è¡Œå¤±è´¥
        """
        try:
            # ä½¿ç”¨æŠ•èµ„ç»„åˆé€‚é…å™¨ï¼Œå®ç°å¤šäº¤æ˜“å¯¹å…±äº«èµ„é‡‘æ± 
            adapter = PortfolioBacktestAdapter(strategy)
            
            if show_progress:
                print(f"\nå¼€å§‹æŠ•èµ„ç»„åˆå›æµ‹ï¼Œäº¤æ˜“å¯¹æ•°é‡: {len(data_dict)}")
                print(f"åˆå§‹æ€»èµ„é‡‘: {config.get('init_cash', 100000.0):.2f}")
                print("-" * 70)
            
            # æ‰§è¡ŒæŠ•èµ„ç»„åˆå›æµ‹ï¼ˆæ‰€æœ‰äº¤æ˜“å¯¹å…±äº«èµ„é‡‘æ± ï¼‰
            results = adapter.run_backtest(
                data=data_dict,
                init_cash=config.get('init_cash', 100000.0),
                fees=config.get('fees', 0.001),
                slippage=config.get('slippage', 0.0001),
                position_size_pct=config.get('position_size_pct', 0.1),
                verbose=self.detail
            )
            
            # ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹æ·»åŠ å…ƒæ•°æ®
            for key in data_dict.keys():
                if key in results:
                    results[key]['symbol'], results[key]['timeframe'] = key.split('_')
                    results[key]['trading_mode'] = config.get('trading_mode', 'spot')
            
            # æ·»åŠ æŠ•èµ„ç»„åˆæ±‡æ€»ä¿¡æ¯
            if 'portfolio' in results:
                portfolio = results['portfolio']
                metrics = portfolio.get('metrics', {})
                
                if show_progress:
                    print(f"\n{'=' * 70}")
                    print("æŠ•èµ„ç»„åˆå›æµ‹å®Œæˆ")
                    print(f"{'=' * 70}")
                    print(f"æœ€ç»ˆæ€»æƒç›Š: {metrics.get('final_equity', 0):.2f}")
                    print(f"æ€»æ”¶ç›Šç‡: {metrics.get('total_return', 0):.2f}%")
                    print(f"æ€»äº¤æ˜“æ¬¡æ•°: {metrics.get('total_trades', 0)}")
                    print(f"èƒœç‡: {metrics.get('win_rate', 0):.2f}%")
                    print(f"æœ€å¤§å›æ’¤: {metrics.get('max_drawdown', 2):.2f}%")
                    print(f"å¤æ™®æ¯”ç‡: {metrics.get('sharpe_ratio', 0):.4f}")
                    print(f"{'=' * 70}")
            
            return results
            
        except Exception as e:
            raise BacktestExecutionError(f"å›æµ‹æ‰§è¡Œå¤±è´¥: {e}")
    
    def save_to_database(
        self,
        results: Dict[str, Any],
        strategy_name: str,
        config: Dict[str, Any]
    ) -> bool:
        """
        ä¿å­˜å›æµ‹ç»“æœåˆ°æ•°æ®åº“
        
        å‚æ•°ï¼š
            results: å›æµ‹ç»“æœ
            strategy_name: ç­–ç•¥åç§°
            config: å›æµ‹é…ç½®
            
        è¿”å›ï¼š
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            from collector.db.database import init_database_config, SessionLocal
            from collector.db.models import BacktestTask, BacktestResult
            from sqlalchemy import func
            
            # åˆå§‹åŒ–æ•°æ®åº“
            init_database_config()
            db = SessionLocal()
            
            try:
                # ä¿å­˜æŠ•èµ„ç»„åˆæ•´ä½“ç»“æœ
                if 'portfolio' in results:
                    portfolio = results['portfolio']
                    portfolio_metrics = portfolio.get('metrics', {})
                    
                    task_id = f"{strategy_name}_portfolio_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    
                    # è·å–æ‰€æœ‰äº¤æ˜“å¯¹
                    symbols = [k for k in results.keys() if k != 'portfolio']
                    
                    backtest_config = {
                        'symbols': symbols,
                        'start_time': config.get('time_range', '').split('-')[0] if config.get('time_range') else None,
                        'end_time': config.get('time_range', '').split('-')[1] if config.get('time_range') else None,
                        'initial_cash': config.get('init_cash', 100000.0),
                        'commission': config.get('fees', 0.001),
                        'slippage': config.get('slippage', 0.0001),
                        'trading_mode': config.get('trading_mode', 'spot'),
                        'strategy_params': config.get('strategy_params', {}),
                        'is_portfolio': True
                    }
                    
                    task = BacktestTask(
                        id=task_id,
                        strategy_name=strategy_name,
                        backtest_config=json.dumps(backtest_config, ensure_ascii=False),
                        status='completed',
                        completed_at=func.now()
                    )
                    db.add(task)
                    
                    result_record = BacktestResult(
                        id=f"{task_id}_result",
                        task_id=task_id,
                        strategy_name=strategy_name,
                        symbol='PORTFOLIO',
                        metrics=json.dumps(portfolio_metrics, ensure_ascii=False, default=str),
                        trades=json.dumps(portfolio.get('trades', []), ensure_ascii=False, default=str),
                        equity_curve=json.dumps(portfolio.get('equity_curve', []), ensure_ascii=False, default=str),
                        strategy_data=json.dumps({}, ensure_ascii=False, default=str)
                    )
                    db.add(result_record)
                    task.result_id = result_record.id
                    
                    logger.info(f"  âœ“ å·²ä¿å­˜æŠ•èµ„ç»„åˆæ•´ä½“å›æµ‹ç»“æœ")
                
                # ä¿å­˜å„äº¤æ˜“å¯¹çš„ç»“æœ
                for key, result in results.items():
                    if key == 'portfolio':
                        continue
                    
                    symbol, timeframe = key.split('_')
                    
                    task_id = f"{strategy_name}_{symbol}_{timeframe}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    
                    backtest_config = {
                        'symbols': [symbol],
                        'interval': timeframe,
                        'start_time': config.get('time_range', '').split('-')[0] if config.get('time_range') else None,
                        'end_time': config.get('time_range', '').split('-')[1] if config.get('time_range') else None,
                        'initial_cash': config.get('init_cash', 100000.0),
                        'commission': config.get('fees', 0.001),
                        'slippage': config.get('slippage', 0.0001),
                        'trading_mode': config.get('trading_mode', 'spot'),
                        'strategy_params': config.get('strategy_params', {}),
                        'is_portfolio_component': True
                    }
                    
                    task = BacktestTask(
                        id=task_id,
                        strategy_name=strategy_name,
                        backtest_config=json.dumps(backtest_config, ensure_ascii=False),
                        status='completed',
                        completed_at=func.now()
                    )
                    db.add(task)
                    
                    result_record = BacktestResult(
                        id=f"{task_id}_result",
                        task_id=task_id,
                        strategy_name=strategy_name,
                        symbol=symbol,
                        metrics=json.dumps(result.get('metrics', {}), ensure_ascii=False, default=str),
                        trades=json.dumps(result.get('trades', []), ensure_ascii=False, default=str),
                        equity_curve=json.dumps(result.get('equity_curve', []), ensure_ascii=False, default=str),
                        strategy_data=json.dumps(result.get('strategy_data', []), ensure_ascii=False, default=str)
                    )
                    db.add(result_record)
                    task.result_id = result_record.id
                    
                    logger.info(f"  âœ“ å·²ä¿å­˜ {symbol} {timeframe} çš„å›æµ‹ç»“æœ")
                
                # æäº¤äº‹åŠ¡
                db.commit()
                logger.info(f"âœ“ æˆåŠŸå°†å›æµ‹ç»“æœä¿å­˜åˆ°æ•°æ®åº“")
                return True
                
            except Exception as e:
                db.rollback()
                logger.error(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                return False
            finally:
                db.close()
                
        except ImportError as e:
            logger.error(f"æ— æ³•å¯¼å…¥æ•°æ®åº“æ¨¡å—: {e}")
            return False
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False


def get_system_config() -> Dict[str, Any]:
    """
    ä»ç³»ç»Ÿé…ç½®è¡¨è¯»å–é»˜è®¤å€¼
    
    è¿”å›ï¼š
        Dict[str, Any]: åŒ…å«é»˜è®¤äº¤æ˜“æ¨¡å¼å’Œæ—¶é—´å‘¨æœŸçš„å­—å…¸
    """
    try:
        from collector.db.connection import get_db_connection
        
        conn = get_db_connection()
        
        # è¯»å–äº¤æ˜“æ¨¡å¼é»˜è®¤å€¼
        trading_mode_config = conn.execute(
            "SELECT value FROM system_config WHERE key = 'default_trading_mode'"
        ).fetchone()
        default_trading_mode = trading_mode_config[0] if trading_mode_config else 'spot'
        
        # è¯»å–æ—¶é—´å‘¨æœŸé»˜è®¤å€¼
        timeframes_config = conn.execute(
            "SELECT value FROM system_config WHERE key = 'default_timeframes'"
        ).fetchone()
        default_timeframes = timeframes_config[0].split(',') if timeframes_config else ['1h']
        
        return {
            'default_trading_mode': default_trading_mode,
            'default_timeframes': default_timeframes
        }
        
    except Exception as e:
        logger.warning(f"ä»ç³»ç»Ÿé…ç½®è¯»å–é»˜è®¤å€¼å¤±è´¥: {e}")
        return {
            'default_trading_mode': 'spot',
            'default_timeframes': ['1h']
        }


def get_symbols_from_data_pool(pool_name: str) -> List[str]:
    """
    ä»æ•°æ®æ± è·å–è‡ªé€‰ç»„åˆçš„è´§å¸å¯¹åˆ—è¡¨
    
    å‚æ•°ï¼š
        pool_name: è‡ªé€‰ç»„åˆåç§°
        
    è¿”å›ï¼š
        List[str]: è´§å¸å¯¹åˆ—è¡¨
        
    å¼‚å¸¸ï¼š
        ValueError: å¦‚æœè‡ªé€‰ç»„åˆä¸å­˜åœ¨æˆ–è·å–å¤±è´¥
    """
    try:
        from collector.db.database import SessionLocal, init_database_config
        from collector.db.models import DataPool, DataPoolAsset
        
        # åˆå§‹åŒ–æ•°æ®åº“
        init_database_config()
        db = SessionLocal()
        
        try:
            # æŸ¥è¯¢è‡ªé€‰ç»„åˆ
            pool = db.query(DataPool).filter_by(name=pool_name).first()
            if not pool:
                raise ValueError(f"è‡ªé€‰ç»„åˆä¸å­˜åœ¨: {pool_name}")
            
            # è·å–è¯¥ç»„åˆä¸‹çš„æ‰€æœ‰èµ„äº§
            assets = db.query(DataPoolAsset).filter_by(pool_id=pool.id).all()
            symbols = [asset.asset_id for asset in assets]
            
            if not symbols:
                logger.warning(f"è‡ªé€‰ç»„åˆ '{pool_name}' ä¸­æ²¡æœ‰è´§å¸å¯¹")
                return []
            
            logger.info(f"ä»è‡ªé€‰ç»„åˆ '{pool_name}' è·å–åˆ° {len(symbols)} ä¸ªè´§å¸å¯¹: {symbols}")
            return symbols
            
        finally:
            db.close()
            
    except Exception as e:
        logger.error(f"ä»è‡ªé€‰ç»„åˆè·å–è´§å¸å¯¹å¤±è´¥: {pool_name}, é”™è¯¯: {e}")
        raise ValueError(f"ä»è‡ªé€‰ç»„åˆè·å–è´§å¸å¯¹å¤±è´¥: {e}")


def generate_test_data(
    n_steps: int = 1000,
    base_price: float = 50000.0,
    volatility: float = 0.001
) -> pd.DataFrame:
    """
    ç”Ÿæˆæµ‹è¯•æ•°æ®
    
    å‚æ•°ï¼š
        n_steps: æ•°æ®æ­¥æ•°
        base_price: åŸºç¡€ä»·æ ¼
        volatility: æ³¢åŠ¨ç‡
        
    è¿”å›ï¼š
        pd.DataFrame: OHLCæ•°æ®
    """
    np.random.seed(42)
    
    # ç”Ÿæˆä»·æ ¼æ•°æ®
    price_changes = np.random.normal(0, volatility, n_steps)
    prices = base_price * (1 + np.cumsum(price_changes))
    
    # ç”Ÿæˆæ—¥æœŸ
    dates = pd.date_range('2024-01-01', periods=n_steps, freq='H')
    
    # åˆ›å»ºOHLCæ•°æ®
    df = pd.DataFrame({
        'Open': prices,
        'High': prices * 1.002,
        'Low': prices * 0.998,
        'Close': prices,
        'Volume': np.random.uniform(100, 1000, n_steps)
    }, index=dates)
    
    return df
